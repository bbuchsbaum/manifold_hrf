# Core Trial-wise Modeling Functions (LS-A and LS-S)
# This file consolidates all core LSS functionality:
# - Fixed component preprocessing (prepare_lss_fixed_components_core)
# - HRF shape reconstruction (reconstruct_hrf_shapes_core)  
# - LS-A (Least Squares All - single GLM) implementations
# - LS-S (Least Squares Separate - per-trial fitting) implementations

#' Prepare LSS Fixed Components (Core)
#'
#' Precomputes fixed regression components for efficient Least Squares Separate 
#' (LSS) estimation using the Woodbury matrix identity.
#'
#' @param A_lss_fixed_matrix An n x q_lss matrix of fixed regressors (e.g., 
#'   intercept, drift terms, nuisance regressors), where n is timepoints and 
#'   q_lss is number of fixed regressors
#' @param intercept_col_index_in_Alss Integer index of the intercept column in 
#'   A_lss_fixed_matrix, or NULL if no intercept
#' @param lambda_ridge_Alss Ridge penalty parameter for regularizing the fixed 
#'   regressor inversion (scalar, typically small like 1e-6)
#'   
#' @return A list containing:
#'   \itemize{
#'     \item \code{P_lss_matrix}: q_lss x n matrix equal to 
#'       (A'A + lambda*I)^(-1) * A'
#'     \item \code{p_lss_vector}: n x 1 vector for intercept projection. If 
#'       intercept_col_index_in_Alss is provided, this is the corresponding 
#'       row of the Moore-Penrose pseudoinverse of A. Otherwise, a zero vector.
#'   }
#'   
#' @details This function implements Component 3, Step 1 of the M-HRF-LSS pipeline.
#'   It precomputes matrices needed for the Woodbury identity-based efficient
#'   computation of single-trial betas. The P_lss matrix projects data onto the
#'   fixed regressor space, while p_lss_vector handles the special case of the
#'   intercept term in the LSS formulation.
#'   
#' @examples
#' \dontrun{
#' # Create example fixed regressors
#' n <- 200  # timepoints
#' 
#' # Intercept + linear drift + motion parameters
#' A_fixed <- cbind(
#'   1,                    # intercept
#'   seq_len(n) / n,       # linear drift
#'   rnorm(n),             # motion param 1
#'   rnorm(n)              # motion param 2
#' )
#' 
#' # Prepare LSS components
#' lss_components <- prepare_lss_fixed_components_core(
#'   A_fixed, 
#'   intercept_col_index_in_Alss = 1,
#'   lambda_ridge_Alss = 1e-6
#' )
#' }
#' 
#' @export
prepare_lss_fixed_components_core <- function(A_lss_fixed_matrix,
                                            intercept_col_index_in_Alss = NULL,
                                            lambda_ridge_Alss = 0) {
  
  # Input validation
  if (!is.matrix(A_lss_fixed_matrix)) {
    stop("A_lss_fixed_matrix must be a matrix")
  }
  
  n <- nrow(A_lss_fixed_matrix)
  q_lss <- ncol(A_lss_fixed_matrix)
  
  if (n < 2) {
    stop("A_lss_fixed_matrix must have at least 2 rows (timepoints)")
  }
  
  if (q_lss < 1) {
    stop("A_lss_fixed_matrix must have at least 1 column")
  }
  
  if (q_lss >= n) {
    stop(sprintf(
      "A_lss_fixed_matrix has too many columns (%d) relative to rows (%d). Must have q_lss < n.",
      q_lss, n
    ))
  }
  
  if (!is.null(intercept_col_index_in_Alss)) {
    if (!is.numeric(intercept_col_index_in_Alss) || 
        length(intercept_col_index_in_Alss) != 1 ||
        intercept_col_index_in_Alss < 1 || 
        intercept_col_index_in_Alss > q_lss ||
        intercept_col_index_in_Alss != round(intercept_col_index_in_Alss)) {
      stop(sprintf(
        "intercept_col_index_in_Alss must be an integer between 1 and %d", 
        q_lss
      ))
    }
  }
  
  lambda_ridge_Alss <- .validate_and_standardize_lambda(lambda_ridge_Alss,
                                                        "lambda_ridge_Alss")
  
  # Step 1: Compute A'A
  AtA <- crossprod(A_lss_fixed_matrix)  # q_lss x q_lss
  
  # Step 2: Add ridge penalty to diagonal
  AtA_reg <- AtA + lambda_ridge_Alss * diag(q_lss)
  
  # Step 3: Check condition number and add jitter if needed
  # This helps with near-singular matrices
  eigvals <- eigen(AtA_reg, symmetric = TRUE, only.values = TRUE)$values
  min_eigval <- min(eigvals)
  max_eigval <- max(eigvals)
  condition_number <- max_eigval / max(min_eigval, .Machine$double.eps)
  
  if (condition_number > 1e8) {
    # Add small jitter to improve conditioning
    jitter <- 1e-6 * median(diag(AtA_reg))
    AtA_reg <- AtA_reg + jitter * diag(q_lss)
    warning(sprintf(
      "Fixed regressor matrix is poorly conditioned (condition number = %.2e). Added jitter = %.2e to diagonal.",
      condition_number, jitter
    ))
  }
  
  # Step 4: Compute P_lss = (A'A + lambda*I)^(-1) * A'
  # Use Cholesky decomposition for stable inversion
  AtA_reg_inv <- chol2inv(chol(AtA_reg))

  # Then multiply by A'
  P_lss_matrix <- AtA_reg_inv %*% t(A_lss_fixed_matrix)  # q_lss x n
  
  # Step 5: Compute p_lss_vector for intercept handling
  if (!is.null(intercept_col_index_in_Alss)) {
    # Compute pseudoinverse of A_lss_fixed_matrix
    # Using the already computed components for efficiency
    # A+ = (A'A)^(-1) * A' when A has full column rank
    # We already have this as P_lss_matrix

    # Extract the row corresponding to the intercept
    p_lss_vector <- P_lss_matrix[intercept_col_index_in_Alss, , drop = TRUE]
  } else {
    # No intercept specified, use zero vector
    p_lss_vector <- rep(0, n)
  }
  
  # Return precomputed components
  list(
    P_lss_matrix = P_lss_matrix,
    p_lss_vector = p_lss_vector
  )
}

#' Reconstruct HRF Shapes from Manifold Coordinates (Core)
#'
#' Reconstructs voxel-specific HRF shapes by multiplying the HRF basis 
#' reconstructor matrix with spatially smoothed manifold coordinates.
#'
#' @param B_reconstructor_matrix The p x m HRF reconstructor matrix from 
#'   Component 0, where p is HRF length and m is manifold dimensionality
#' @param Xi_smoothed_matrix The m x V matrix of spatially smoothed manifold 
#'   coordinates from Component 2, where V is number of voxels
#'   
#' @return H_shapes_allvox_matrix A p x V matrix where each column is the 
#'   reconstructed HRF shape for a voxel
#'   
#' @details This function implements Component 3, Step 2 of the M-HRF-LSS pipeline.
#'   It transforms the low-dimensional manifold representation back to the full
#'   HRF shape space. The resulting HRF shapes are used to create voxel-specific
#'   regressors for the LSS estimation.
#'   
#' @examples
#' \dontrun{
#' # Example with synthetic data
#' p <- 30   # HRF length
#' m <- 5    # manifold dimensions
#' V <- 100  # voxels
#' 
#' # Example reconstructor (would come from Component 0)
#' B_reconstructor <- matrix(rnorm(p * m), p, m)
#' 
#' # Example smoothed manifold coordinates (would come from Component 2)
#' Xi_smoothed <- matrix(rnorm(m * V), m, V)
#' 
#' # Reconstruct HRF shapes
#' H_shapes <- reconstruct_hrf_shapes_core(B_reconstructor, Xi_smoothed)
#' # Result is 30 x 100 matrix (HRF samples x voxels)
#' }
#' 
#' @export
reconstruct_hrf_shapes_core <- function(B_reconstructor_matrix,
                                      Xi_smoothed_matrix) {
  
  # Input validation
  if (!is.matrix(B_reconstructor_matrix)) {
    stop("B_reconstructor_matrix must be a matrix")
  }
  
  if (!is.matrix(Xi_smoothed_matrix)) {
    stop("Xi_smoothed_matrix must be a matrix")
  }
  
  # Get dimensions
  p <- nrow(B_reconstructor_matrix)
  m_B <- ncol(B_reconstructor_matrix)
  m_Xi <- nrow(Xi_smoothed_matrix)
  V <- ncol(Xi_smoothed_matrix)
  
  # Check dimension compatibility
  if (m_B != m_Xi) {
    stop(sprintf(
      "Dimension mismatch: B_reconstructor_matrix has %d columns but Xi_smoothed_matrix has %d rows",
      m_B, m_Xi
    ))
  }
  
  if (p < 2) {
    stop("B_reconstructor_matrix must have at least 2 rows (HRF time points)")
  }
  
  if (m_B < 1) {
    stop("B_reconstructor_matrix must have at least 1 column (manifold dimension)")
  }
  
  if (V < 1) {
    stop("Xi_smoothed_matrix must have at least 1 column (voxel)")
  }
  
  # Reconstruct HRF shapes
  # H = B * Xi
  # where B is p x m and Xi is m x V
  # resulting in H that is p x V
  H_shapes_allvox_matrix <- B_reconstructor_matrix %*% Xi_smoothed_matrix
  
  # Ensure the result is a regular matrix (not Matrix class)
  if (inherits(H_shapes_allvox_matrix, "Matrix")) {
    H_shapes_allvox_matrix <- as.matrix(H_shapes_allvox_matrix)
  }
  
  return(H_shapes_allvox_matrix)
}

#' Run LSS for Single Voxel - Simple Interface
#'
#' Simplified interface for trial-wise LSS that handles projection internally
#'
#' @param y_voxel Data vector for single voxel (n x 1)
#' @param X_trial_list List of trial matrices (n x p each)
#' @param h_voxel HRF shape vector (p x 1)
#' @param TR Repetition time in seconds (currently unused)
#' @return List with beta_trials vector
#' @export
run_lss_for_voxel_corrected <- function(y_voxel,
                                       X_trial_list,
                                       h_voxel,
                                       TR = 2) {

  n <- length(y_voxel)
  T_trials <- length(X_trial_list)

  # Create convolved regressors
  C <- matrix(0, n, T_trials)
  for (t in seq_len(T_trials)) {
    C[, t] <- X_trial_list[[t]] %*% h_voxel
  }

  # Project out intercept
  X_base <- matrix(1, n, 1)
  P_base <- MASS::ginv(X_base)
  Q_base <- diag(n) - X_base %*% P_base
  y_res <- Q_base %*% y_voxel
  Q_dmat <- Q_base %*% C

  betas <- lss_compute_r(Q_dmat, as.matrix(y_res))
  list(beta_trials = as.vector(betas))
}


#' Compute LSS Betas for a Single Voxel
#'
#' Internal helper used by LSS functions to compute trial-wise betas using
#' efficient projection without forming the full n x n matrix.
#'
#' @param C_v Matrix of convolved trial regressors (n x T)
#' @param Y_v Numeric vector of length n with projected voxel data
#' @param A_fixed Fixed regressors matrix used during projection (n x q)
#' @param P_lss Precomputed matrix from `prepare_lss_fixed_components_core`
#'              with dimensions q x n
#' @param p_lss Precomputed intercept projection vector of length n (unused)
#' @return Numeric vector of length T containing LSS beta estimates
#' @keywords internal
.compute_lss_betas <- function(C_v, Y_v, A_fixed, P_lss, p_lss) {
  # Efficient projection: Q_dmat = C_v - A_fixed %*% (P_lss %*% C_v)
  # This avoids forming the n x n matrix P_confound = I - A_fixed %*% P_lss
  Q_dmat <- C_v - A_fixed %*% (P_lss %*% C_v)
  lss_compute_r(Q_dmat, as.matrix(Y_v))
}


#' LS-A Beta Computation 
#'
#' Solves the ordinary least squares problem using single GLM: (C'C)^-1 C'y
#'
#' @param C Design matrix (n x T)
#' @param y Response vector (n x 1)  
#' @return Vector of beta estimates (T x 1)
#' @keywords internal
.lsa_beta <- function(C, y) {
  XtX <- crossprod(C)
  if (qr(XtX)$rank < ncol(C)) {
    warning("Design matrix is not full rank")
  }
  drop(solve(XtX, crossprod(C, y)))
}

#' Factor out shared confound projection logic
#'
#' @param y Vector or matrix to project
#' @param C Design matrix to project  
#' @param Z Confound matrix (n x q). If NULL, no projection applied.
#' @param lambda Ridge regularization parameter
#' @return List with projected y and C
#' @keywords internal
.project_confounds <- function(y, C, Z = NULL, lambda = 0) {
  # Automatically add intercept if not present
  if (is.null(Z) || ncol(Z) == 0) {
    Z <- matrix(1, nrow = length(y), ncol = 1, dimnames = list(NULL, "Intercept"))
  } else {
    # Check if intercept already exists (constant column with var=0)
    has_intercept <- any(apply(Z, 2, var) == 0)
    if (!has_intercept) {
      Z <- cbind(Intercept = 1, Z)
    }
  }
  
  Zinv <- solve(crossprod(Z) + lambda * diag(ncol(Z)))
  y_out <- y - Z %*% (Zinv %*% crossprod(Z, y))
  C_out <- C - Z %*% (Zinv %*% crossprod(Z, C))
  list(y = y_out, C = C_out)
}

#' Compute LS-S (Least Squares Separate) Beta Series
#'
#' Vectorized implementation of the LS-S algorithm following Mumford et al.
#' 
#' @param y Response vector (n x 1)
#' @param C Design matrix (n x T) with trial regressors  
#' @param eps Numerical stability threshold
#' @return Vector of trial-wise beta estimates (T x 1)
#' @keywords internal
.compute_lss_beta_series <- function(y, C, eps = 1e-10) {
  n <- nrow(C) 
  T <- ncol(C)
  
  # Simple approach: for each trial, fit y ~ c_t + intercept using OLS
  betas <- numeric(T)
  for (t in seq_len(T)) {
    c_t <- C[, t]
    
    # Create design matrix with intercept and trial regressor
    X_t <- cbind(Intercept = 1, Trial = c_t)
    
    # Check if regressor has variance
    if (var(c_t) < eps) {
      betas[t] <- 0  # No variance in regressor
    } else {
      # Solve normal equations: (X'X)^-1 X'y
      XtX <- crossprod(X_t)
      if (qr(XtX)$rank < ncol(X_t)) {
        betas[t] <- 0  # Rank deficient
      } else {
        coefs <- solve(XtX, crossprod(X_t, y))
        betas[t] <- coefs[2]  # Extract trial coefficient (not intercept)
      }
    }
  }
  
  betas
}

#' Run LS-A for Single Voxel - Full Interface
#'
#' Complete LS-A (Least Squares All) interface that uses precomputed components.
#' This fits all trials simultaneously in a single GLM.
#'
#' @param Y_proj_voxel_vector Projected data (n x 1) with confounds removed
#' @param X_trial_onset_list_of_matrices List of unprojected trial matrices (n x p each)
#' @param H_shape_voxel_vector HRF shape (p x 1)
#' @param A_lss_fixed_matrix Matrix of fixed regressors used during projection (n x q)
#' @param P_lss_matrix Precomputed matrix from \code{prepare_lss_fixed_components_core}
#'   with dimensions q x n
#' @param p_lss_vector Precomputed intercept projection vector of length n
#' @return Vector of trial-wise betas
#' @export
run_lsa_for_voxel_corrected_full <- function(Y_proj_voxel_vector,
                                            X_trial_onset_list_of_matrices,
                                            H_shape_voxel_vector,
                                            A_lss_fixed_matrix,
                                            P_lss_matrix,
                                            p_lss_vector) {
  
  n <- length(Y_proj_voxel_vector)
  T_trials <- length(X_trial_onset_list_of_matrices)
  p <- length(H_shape_voxel_vector)
  
  # Validate inputs
  if (T_trials == 0) {
    stop("X_trial_onset_list_of_matrices cannot be empty")
  }
  
  # Step 1: Create all trial regressors
  C <- matrix(0, n, T_trials)
  for (t in seq_len(T_trials)) {
    C[, t] <- X_trial_onset_list_of_matrices[[t]] %*% H_shape_voxel_vector
  }

  # Check for rank deficiency
  qr_C <- qr(C)
  if (qr_C$rank < T_trials) {
    warning(
      sprintf(
        "Trial regressors are rank deficient for this voxel: rank %d < %d",
        qr_C$rank,
        T_trials
      )
    )
  }
  
  # Apply fixed confound projection manually (legacy interface)
  Q_dmat <- C - A_lss_fixed_matrix %*% (P_lss_matrix %*% C)
  
  # Compute LS-A betas via single GLM  
  .lsa_beta(Q_dmat, Y_proj_voxel_vector)
}

#' @rdname run_lsa_for_voxel_corrected_full
#' @export  
run_lss_for_voxel_corrected_full <- function(Y_proj_voxel_vector,
                                            X_trial_onset_list_of_matrices,
                                            H_shape_voxel_vector,
                                            A_lss_fixed_matrix,
                                            P_lss_matrix,
                                            p_lss_vector) {
  .Deprecated("run_lsa_for_voxel_corrected_full")
  run_lsa_for_voxel_corrected_full(Y_proj_voxel_vector,
                                  X_trial_onset_list_of_matrices,
                                  H_shape_voxel_vector,
                                  A_lss_fixed_matrix,
                                  P_lss_matrix,
                                  p_lss_vector)
}


#' Run LS-A Woodbury for Single Voxel  
#'
#' Memory-efficient LS-A (Least Squares All) implementation using Woodbury matrix identity.
#' Avoids building the full n×n projection matrix for better performance.
#' Fits all trials simultaneously in a single GLM.
#'
#' @param Y_proj_voxel_vector Projected data vector (n x 1)
#' @param X_trial_onset_list_of_matrices List of trial design matrices
#' @param H_shape_voxel_vector HRF shape vector (p x 1)
#' @param Z_confounds Confound matrix (n x q). If \code{NULL}, no projection is applied.
#' @param lambda Ridge regularization parameter (default 0 for parity with corrected_full)
#' @return Vector of trial-wise betas
#' @export
run_lsa_woodbury <- function(Y_proj_voxel_vector,
                            X_trial_onset_list_of_matrices,
                            H_shape_voxel_vector,
                            Z_confounds = NULL,
                            lambda = 0) {
  
  n <- length(Y_proj_voxel_vector)
  T_trials <- length(X_trial_onset_list_of_matrices)

  # 1. Build trial regressors
  C <- matrix(0, n, T_trials)
  for (t in seq_len(T_trials)) {
    C[, t] <- X_trial_onset_list_of_matrices[[t]] %*% H_shape_voxel_vector
  }

  # 2. Apply confound projection using efficient helper
  proj <- .project_confounds(Y_proj_voxel_vector, C, Z_confounds, lambda)

  # 3. Compute LS-A betas via single GLM
  .lsa_beta(proj$C, proj$y)
}

#' Run LSS Woodbury for Single Voxel (Deprecated Interface)
#'
#' This function maintains backward compatibility for tests that use the old
#' P_confound parameter instead of Z_confounds.
#'
#' @param Y_proj_voxel_vector Projected data vector (n x 1)
#' @param X_trial_onset_list_of_matrices List of trial design matrices
#' @param H_shape_voxel_vector HRF shape vector (p x 1)
#' @param P_confound Projection matrix (n x n) - deprecated, use Z_confounds
#' @param Z_confounds Confound matrix (n x q). If \code{NULL}, no projection is applied.
#' @param lambda Ridge regularization parameter (default 0)
#' @return Vector of trial-wise betas
#' @export
run_lss_woodbury_corrected <- function(Y_proj_voxel_vector,
                                      X_trial_onset_list_of_matrices,
                                      H_shape_voxel_vector,
                                      P_confound = NULL,
                                      Z_confounds = NULL,
                                      lambda = 0) {
  
  # Handle backward compatibility
  if (!is.null(P_confound) && is.null(Z_confounds)) {
    # Old interface using projection matrix directly
    # We need to apply the projection manually since we can't extract Z from P
    n <- length(Y_proj_voxel_vector)
    T_trials <- length(X_trial_onset_list_of_matrices)
    
    # Build convolved trial regressors
    C <- matrix(0, n, T_trials)
    for (t in seq_len(T_trials)) {
      C[, t] <- X_trial_onset_list_of_matrices[[t]] %*% H_shape_voxel_vector
    }
    
    # Apply projection if provided
    if (!is.null(P_confound)) {
      Y_proj <- P_confound %*% Y_proj_voxel_vector
      C_proj <- P_confound %*% C
    } else {
      Y_proj <- Y_proj_voxel_vector
      C_proj <- C
    }
    
    # Compute LSS betas using fmrilss
    return(as.vector(lss_compute_r(C_proj, as.matrix(Y_proj))))
  }
  
  # New interface - use run_lss_for_voxel
  run_lss_for_voxel(
    y_voxel = Y_proj_voxel_vector,
    X_trial_list = X_trial_onset_list_of_matrices,
    h_voxel = H_shape_voxel_vector,
    Z_confounds = Z_confounds,
    lambda = lambda
  )$beta_trials
}


#' Prepare Projection Matrix
#'
#' Creates a projection matrix that removes confound space.
#' This function is deprecated; use .project_confounds() for better efficiency.
#'
#' @param Z_confounds Confound matrix (n x q)
#' @param lambda Ridge regularization parameter
#' @return Projection matrix (n x n)
#' @export
prepare_projection_matrix <- function(Z_confounds, lambda = 1e-6) {
  .Deprecated(".project_confounds")
  
  n <- nrow(Z_confounds)
  q <- ncol(Z_confounds)
  
  if (q == 0) {
    # No confounds - return identity
    return(diag(n))
  }
  
  # Regularized projection: P = I - Z(Z'Z + λI)^(-1)Z'
  ZTZ <- crossprod(Z_confounds)
  ZTZ_reg <- ZTZ + lambda * diag(q)
  
  # Use Woodbury identity for stability
  ZTZ_inv <- solve(ZTZ_reg)
  P_confound <- diag(n) - Z_confounds %*% ZTZ_inv %*% t(Z_confounds)
  
  return(P_confound)
}

#' Run LS-S for Single Voxel
#'
#' LS-S (Least Squares Separate) fits each trial separately, regressing out all other trials.
#' This is the standard approach for MVPA and rapid event-related designs.
#'
#' @param y_voxel Response vector for single voxel (n x 1)
#' @param X_trial_list List of trial design matrices (n x p each)
#' @param h_voxel HRF shape vector (p x 1)  
#' @param Z_confounds Confound matrix (n x q). If \code{NULL}, no projection applied.
#' @param lambda Ridge regularization parameter (default 0)
#' @return List with beta_trials vector (T x 1)
#' @export
run_lss_for_voxel <- function(y_voxel,
                              X_trial_list,
                              h_voxel,
                              Z_confounds = NULL,
                              lambda = 0) {

  # 1. Build C
  n <- length(y_voxel)
  Tt <- length(X_trial_list)
  C <- matrix(0, n, Tt)
  for (t in seq_len(Tt)) C[, t] <- X_trial_list[[t]] %*% h_voxel

  # 2. Project out confounds only (LS-S handles intercept per-trial)
  if (is.null(Z_confounds) || ncol(Z_confounds) == 0) {
    proj_y <- y_voxel
    proj_C <- C
  } else {
    Zinv <- solve(crossprod(Z_confounds) + lambda * diag(ncol(Z_confounds)))
    proj_y <- y_voxel - Z_confounds %*% (Zinv %*% crossprod(Z_confounds, y_voxel))
    proj_C <- C - Z_confounds %*% (Zinv %*% crossprod(Z_confounds, C))
  }

  # 3. LS-S coefficients (intercept handled per-trial)
  bet <- .compute_lss_beta_series(proj_y, proj_C)
  list(beta_trials = bet)
}

#' Run LS-S Across Multiple Voxels
#'
#' Vectorized LS-S (Least Squares Separate) for multiple voxels.
#' Each trial is fit separately, regressing out all other trials.
#'
#' @param Y_matrix Response matrix (n x V) for V voxels
#' @param X_trial_list List of trial design matrices (n x p each)
#' @param H_matrix HRF shape matrix (p x V)
#' @param Z_confounds Confound matrix (n x q). If \code{NULL}, no projection applied.
#' @param lambda Ridge regularization parameter (default 0)
#' @return Matrix of trial-wise betas (T x V)
#' @export
run_lss_voxel_loop <- function(Y_matrix,
                               X_trial_list,
                               H_matrix,
                               Z_confounds = NULL,
                               lambda = 0) {
  
  T_trials <- length(X_trial_list)
  V <- ncol(Y_matrix)
  Beta <- matrix(0, T_trials, V)
  
  for (v in seq_len(V)) {
    result <- run_lss_for_voxel(
      y_voxel = Y_matrix[, v],
      X_trial_list = X_trial_list,
      h_voxel = H_matrix[, v],
      Z_confounds = Z_confounds,
      lambda = lambda
    )
    Beta[, v] <- result$beta_trials
  }
  
  Beta
}
#' Run LS-A Across Voxels (Core)
#'
#' Computes trial-wise LS-A (Least Squares All) estimates for all voxels using the
#' corrected full implementation. Fits all trials simultaneously in a single GLM.
#'
#' @param Y_proj_matrix n x V projected BOLD data matrix.
#' @param X_trial_onset_list_of_matrices List of length T with n x p design matrices.
#' @param H_shapes_allvox_matrix p x V matrix of HRF shapes.
#' @param A_lss_fixed_matrix n x q matrix of fixed regressors.
#' @param P_lss_matrix q x n matrix from \code{prepare_lss_fixed_components_core}.
#' @param p_lss_vector Intercept projection vector from \code{prepare_lss_fixed_components_core}.
#' @param n_jobs Number of parallel workers for voxel-wise computation.
#' @param ram_heuristic_GB_for_Rt RAM limit in gigabytes (currently unused).
#' 
#' @return A T x V matrix of trial-wise beta estimates.
#' @export
run_lsa_voxel_loop <- function(Y_proj_matrix,
                              X_trial_onset_list_of_matrices,
                              H_shapes_allvox_matrix,
                              A_lss_fixed_matrix,
                              P_lss_matrix,
                              p_lss_vector,
                              n_jobs = 1,
                              ram_heuristic_GB_for_Rt = 1.0) {

  if (!is.matrix(Y_proj_matrix)) {
    stop("Y_proj_matrix must be a matrix")
  }

  n <- nrow(Y_proj_matrix)
  V <- ncol(Y_proj_matrix)

  design_info <- validate_design_matrix_list(
    X_trial_onset_list_of_matrices,
    n_timepoints = n
  )
  T_trials <- design_info$k

  validate_hrf_shape_matrix(
    H_shapes_allvox_matrix,
    n_timepoints = design_info$p,
    n_voxels = V
  )

  voxel_fun <- function(v) {
    tryCatch({
      run_lsa_for_voxel_corrected_full(
        Y_proj_voxel_vector = Y_proj_matrix[, v],
        X_trial_onset_list_of_matrices = X_trial_onset_list_of_matrices,
        H_shape_voxel_vector = H_shapes_allvox_matrix[, v],
        A_lss_fixed_matrix = A_lss_fixed_matrix,
        P_lss_matrix = P_lss_matrix,
        p_lss_vector = p_lss_vector
      )
    }, error = function(e) {
      warning(sprintf("LS-A failed for voxel %d: %s", v, e$message))
      # Return a vector of NAs with the correct length
      rep(NA_real_, T_trials)
    })
  }

  res_list <- .parallel_lapply(seq_len(V), voxel_fun, n_jobs)
  do.call(cbind, res_list)
}

#' Run LSS Across Voxels (Core)
#'
#' Computes trial-wise LSS (Least Squares Separate) estimates for all voxels.
#' This is the true LSS implementation where each trial is fit separately.
#'
#' @param Y_proj_matrix n x V projected BOLD data matrix.
#' @param X_trial_onset_list_of_matrices List of length T with n x p design matrices.
#' @param H_shapes_allvox_matrix p x V matrix of HRF shapes.
#' @param A_lss_fixed_matrix n x q matrix of fixed regressors.
#' @param P_lss_matrix q x n matrix from \code{prepare_lss_fixed_components_core}.
#' @param p_lss_vector Intercept projection vector from \code{prepare_lss_fixed_components_core}.
#' @param n_jobs Number of parallel workers for voxel-wise computation.
#' @param ram_heuristic_GB_for_Rt RAM limit in gigabytes (currently unused).
#' 
#' @return A T x V matrix of trial-wise beta estimates.
#' @export
run_lss_voxel_loop_core <- function(Y_proj_matrix,
                                   X_trial_onset_list_of_matrices,
                                   H_shapes_allvox_matrix,
                                   A_lss_fixed_matrix,
                                   P_lss_matrix,
                                   p_lss_vector,
                                   n_jobs = 1,
                                   ram_heuristic_GB_for_Rt = 1.0) {

  if (!is.matrix(Y_proj_matrix)) {
    stop("Y_proj_matrix must be a matrix")
  }

  n <- nrow(Y_proj_matrix)
  V <- ncol(Y_proj_matrix)

  design_info <- validate_design_matrix_list(
    X_trial_onset_list_of_matrices,
    n_timepoints = n
  )
  T_trials <- design_info$k

  validate_hrf_shape_matrix(
    H_shapes_allvox_matrix,
    n_timepoints = design_info$p,
    n_voxels = V
  )

  voxel_fun <- function(v) {
    tryCatch({
      # First create convolved regressors
      C <- matrix(0, n, T_trials)
      for (t in seq_len(T_trials)) {
        C[, t] <- X_trial_onset_list_of_matrices[[t]] %*% H_shapes_allvox_matrix[, v]
      }
      
      # Apply the projection using the precomputed matrices
      # This is equivalent to: (I - A_fixed %*% P_lss) %*% Y
      Y_v_proj <- Y_proj_matrix[, v] - A_lss_fixed_matrix %*% (P_lss_matrix %*% Y_proj_matrix[, v])
      C_proj <- C - A_lss_fixed_matrix %*% (P_lss_matrix %*% C)
      
      # Use LSS computation
      as.vector(lss_compute_r(C_proj, as.matrix(Y_v_proj)))
    }, error = function(e) {
      warning(sprintf("LSS failed for voxel %d: %s", v, e$message))
      # Return a vector of NAs with the correct length
      rep(NA_real_, T_trials)
    })
  }

  res_list <- .parallel_lapply(seq_len(V), voxel_fun, n_jobs)
  do.call(cbind, res_list)
}
